{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbc00f06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T17:48:47.748860Z",
     "iopub.status.busy": "2026-01-10T17:48:47.748612Z",
     "iopub.status.idle": "2026-01-10T17:49:21.373290Z",
     "shell.execute_reply": "2026-01-10T17:49:21.372303Z"
    },
    "papermill": {
     "duration": 33.62883,
     "end_time": "2026-01-10T17:49:21.374681",
     "exception": false,
     "start_time": "2026-01-10T17:48:47.745851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m643.4/643.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.6/18.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for deeplake (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "datasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "s3fs 2025.3.0 requires fsspec==2025.3.0.*, but you have fsspec 2025.10.0 which is incompatible.\r\n",
      "ypy-websocket 0.8.4 requires aiofiles<23,>=22.1.0, but you have aiofiles 25.1.0 which is incompatible.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "ibis-framework 9.5.0 requires toolz<1,>=0.11, but you have toolz 1.1.0 which is incompatible.\r\n",
      "gradio 5.38.1 requires aiofiles<25.0,>=22.0, but you have aiofiles 25.1.0 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\r\n",
      "jupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mCloning into 'NeurIPS2025-LEAR'...\r\n",
      "remote: Enumerating objects: 519, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (519/519), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (366/366), done.\u001b[K\r\n",
      "remote: Total 519 (delta 191), reused 421 (delta 112), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (519/519), 6.69 MiB | 17.94 MiB/s, done.\r\n",
      "Resolving deltas: 100% (191/191), done.\r\n",
      "/kaggle/working/NeurIPS2025-LEAR\n"
     ]
    }
   ],
   "source": [
    "!pip install -q deeplake==3.9.52 onedrivedownloader\n",
    "!git clone https://github.com/nqh-tq-32052503/NeurIPS2025-LEAR.git\n",
    "%cd /kaggle/working/NeurIPS2025-LEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ce2c66a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T17:49:21.389248Z",
     "iopub.status.busy": "2026-01-10T17:49:21.388639Z",
     "iopub.status.idle": "2026-01-10T17:49:21.394481Z",
     "shell.execute_reply": "2026-01-10T17:49:21.393809Z"
    },
    "papermill": {
     "duration": 0.014064,
     "end_time": "2026-01-10T17:49:21.395506",
     "exception": false,
     "start_time": "2026-01-10T17:49:21.381442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "origin_params = {\n",
    "    \"list_datasets\" : \"seq-cifar100,seq-cifar100,seq-cifar100\",\n",
    "    \"dataset\" : \"seq-cifar100\",\n",
    "    \"ncls_per_task\" : 5,\n",
    "    \"model\" : \"LEAR\",\n",
    "    \"lr\" : 0.03,\n",
    "    \"batch_size\" : 32,\n",
    "    \"n_epochs\" : 5,\n",
    "    \"num_workers\" : 8,\n",
    "    \"backbone\" : \"lear\",\n",
    "    \"transform_type\" : \"weak\",\n",
    "    \"use_bilora\" : 1\n",
    "}\n",
    "\n",
    "list1 = [\"local\", \"both\"]\n",
    "list2 = [\"separate\", \"aggregate\"]\n",
    "list3 = [0, 1]\n",
    "combinations = [(x, y, z) for x in list1 for y in list2 for z in list3]\n",
    "\n",
    "#     \"apply_bilora_for\" : \"local\",\n",
    "#    \"bilora_mode\" : \"aggregate\",\n",
    "#    \"skip_task_0\" : 0\n",
    "\n",
    "list_params = []\n",
    "for combination in combinations:\n",
    "    params = copy.deepcopy(origin_params)\n",
    "    params[\"apply_bilora_for\"] = combination[0]\n",
    "    params[\"bilora_mode\"] = combination[1]\n",
    "    params[\"skip_task_0\"] = combination[2]\n",
    "    list_params.append(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4e47ce7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T17:49:21.408970Z",
     "iopub.status.busy": "2026-01-10T17:49:21.408579Z",
     "iopub.status.idle": "2026-01-10T17:49:21.412126Z",
     "shell.execute_reply": "2026-01-10T17:49:21.411578Z"
    },
    "papermill": {
     "duration": 0.011441,
     "end_time": "2026-01-10T17:49:21.413090",
     "exception": false,
     "start_time": "2026-01-10T17:49:21.401649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_cmds = []\n",
    "for params in list_params:\n",
    "    cmd = \"python main_domain.py\"\n",
    "    for key in params:\n",
    "        param_cmd = f\" --{key} {params[key]}\"\n",
    "        cmd += param_cmd\n",
    "    list_cmds.append(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40f8f68b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T17:49:21.426666Z",
     "iopub.status.busy": "2026-01-10T17:49:21.426180Z",
     "iopub.status.idle": "2026-01-10T20:26:59.547609Z",
     "shell.execute_reply": "2026-01-10T20:26:59.546845Z"
    },
    "papermill": {
     "duration": 9458.129787,
     "end_time": "2026-01-10T20:26:59.549044",
     "exception": false,
     "start_time": "2026-01-10T17:49:21.419257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO CMD] Running:  python main_domain.py --list_datasets seq-cifar100,seq-cifar100,seq-cifar100 --dataset seq-cifar100 --ncls_per_task 5 --model LEAR --lr 0.03 --batch_size 32 --n_epochs 5 --num_workers 8 --backbone lear --transform_type weak --use_bilora 1 --apply_bilora_for local --bilora_mode separate --skip_task_0 0\n",
      "[INFO] 10-Jan-26 17:49:24 - Running Mammoth! on 04dc83e5ff9c. (if you see this message more than once, you are probably importing something wrong)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 10-Jan-26 17:49:34 - NumExpr defaulting to 4 threads.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (4.4.4) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] 10-Jan-26 17:49:38 - Trying to load default configuration for model LEAR but no configuration file found in None.\n",
      "[WARNING] 10-Jan-26 17:49:38 - Default configuration file not found for dataset seq-cifar100. Using the defaults specified in the dataset class (if available).\n",
      "[INFO] 10-Jan-26 17:49:38 - `lr_scheduler` set to multisteplr, overrides default from dataset.\n",
      "[INFO] 10-Jan-26 17:49:38 - Using device cuda:0\n",
      "Loading dataset: seq-cifar100\n",
      "Loading dataset: seq-cifar100\n",
      "Loading dataset: seq-cifar100\n",
      "[INFO] 10-Jan-26 17:49:38 - `wandb_entity` and `wandb_project` not set. Disabling wandb.\n",
      "[WARNING] 10-Jan-26 17:49:38 - Label noise is not available with multi-label datasets. If this is not multi-label, ignore this warning.\n",
      "[INFO] 10-Jan-26 17:49:39 - Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)\n",
      "[INFO] 10-Jan-26 17:49:45 - [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "[INFO] 10-Jan-26 17:49:45 - Missing keys (head.weight, head.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n",
      "[INFO] 10-Jan-26 17:49:46 - Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)\n",
      "[INFO] 10-Jan-26 17:49:47 - [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "[INFO] 10-Jan-26 17:49:47 - Missing keys (head.weight, head.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n",
      "[INFO] 10-Jan-26 17:49:47 - Using backbone: lear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LEAR as backbone\n",
      "Use BiLORA:  True\n",
      "Apply BiLORA for:  local\n",
      "Namespace(dataset='seq-cifar100', model='LEAR', backbone='lear', load_best_args=False, dataset_config=None, model_config='default', list_datasets='seq-cifar100,seq-cifar100,seq-cifar100', transform_type='weak', ncls_per_task=5, use_bilora=1, apply_bilora_for='local', skip_task_0=0, bilora_mode='separate', num_classes=100, seed=None, permute_classes=False, base_path='./data/', results_path='results/', device=device(type='cuda', index=0), notes=None, eval_epochs=None, non_verbose=False, disable_log=False, num_workers=8, enable_other_metrics=False, debug_mode=False, inference_only=False, code_optimization=0, distributed='no', savecheck=None, save_checkpoint_mode='safe', loadcheck=None, ckpt_name=None, start_from=None, stop_after=None, wandb_name=None, wandb_entity=None, wandb_project=None, lr=0.03, batch_size=32, label_perc=1.0, label_perc_by_class=1.0, joint=0, eval_future=False, validation=None, validation_mode='current', fitting_mode='epochs', early_stopping_patience=5, early_stopping_metric='loss', early_stopping_freq=1, early_stopping_epsilon=1e-06, n_epochs=5, n_iters=None, optimizer='sgd', optim_wd=0.0, optim_mom=0.0, optim_nesterov=False, drop_last=False, lr_scheduler='multisteplr', scheduler_mode='epoch', lr_milestones=[35, 45], sched_multistep_lr_gamma=0.1, noise_type='symmetric', noise_rate=0.0, disable_noisy_labels_cache=False, cache_path_noisy_labels='noisy_labels', conf_jobnum='734eea9a-b1bf-4056-9f75-e5cedc8326ff', conf_timestamp='2026-01-10 17:49:38.087460', conf_host='04dc83e5ff9c', conf_git_hash='d9141df2a3954ab461ad96da8cee30a4693fe2d0', minibatch_size=32, nowand=1)\n",
      "begin task 1, dataset:seq-cifar100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169M/169M [00:14<00:00, 11.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target classes:  [81, 92, 17, 22, 21]\n",
      "[INFO] 10-Jan-26 17:50:06 - Using 8 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target classes:  [81, 92, 17, 22, 21]\n",
      "[INFO] 10-Jan-26 17:50:07 - Using 8 workers for the dataloader.\n",
      "Applying BiLORA technique for current task:  0  at index:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 1 - Epoch 5: 100%|███████████████████████████████████████████████████████████████████████████████████████| 390/390 [04:59<00:00,  1.30it/s, loss_ce=0.000172, loss_nor=-0.0323, lr=0.03, ep/h=60.5]\n",
      "Calculate distribution for task 1:  78%|███████▊  | 78/100 [00:14<00:04,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose experts for evaluate: [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 1:  20%|███████████████████▊                                                                               | 3/15 [00:02<00:08,  1.37it/s, acc_task_1=100]\n",
      "Accuracy for 1 task(s): \t [Class-IL]: 100.0 % \t [Task-IL]: 0.0 %\n",
      "\tRaw accuracy values: Class-IL [100.0] | Task-IL [0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  1  at index:  0\n",
      "Applying BiLORA technique for current task:  1  at index:  0\n",
      "Applying BiLORA technique for current task:  1  at index:  0\n",
      "begin task 2, dataset:seq-cifar100\n",
      "target classes:  [46, 79, 2, 40, 27]\n",
      "[INFO] 10-Jan-26 17:55:26 - Using 8 workers for the dataloader.\n",
      "target classes:  [46, 79, 2, 40, 27]\n",
      "[INFO] 10-Jan-26 17:55:27 - Using 8 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Choose params for task 2: 100%|██████████| 50/50 [00:09<00:00,  5.07it/s, distances=[0.59]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load expert 1 parameters\n",
      "Create new expert 2\n",
      "Applying BiLORA technique for current task:  1  at index:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 2 - Epoch 5: 100%|███████████████████████████████████████████████████████████| 390/390 [05:38<00:00,  1.15it/s, loss_ce=0.0466, loss_kd=-0.965, loss_nor=-0.0307, loss_mi=3.73, lr=0.03, ep/h=53.9]\n",
      "Calculate distribution for task 2:  78%|███████▊  | 78/100 [00:14<00:04,  5.29it/s]\n",
      "Choose expert for evaluate: 100%|████████████████████████████████████████████████████████████████████████| 30/30 [00:06<00:00,  4.53it/s, task 2=2, distance=[2.98, 2.03]]\n",
      "Evaluating:   0%|                                                                                                                                  | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose experts for evaluate: [1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 1:  10%|█████████▊                                                                                        | 3/30 [00:01<00:15,  1.76it/s, acc_task_1=20.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  2  at index:  0\n",
      "Applying BiLORA technique for current task:  2  at index:  0\n",
      "Applying BiLORA technique for current task:  2  at index:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 2:  20%|███████████████████▌                                                                              | 6/30 [00:03<00:15,  1.58it/s, acc_task_2=87.5]\n",
      "Accuracy for 2 task(s): \t [Class-IL]: 54.17 % \t [Task-IL]: 0.0 %\n",
      "\tRaw accuracy values: Class-IL [20.833333333333336, 87.5] | Task-IL [0, 0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  2  at index:  1\n",
      "Applying BiLORA technique for current task:  2  at index:  1\n",
      "Applying BiLORA technique for current task:  2  at index:  1\n",
      "begin task 3, dataset:seq-cifar100\n",
      "target classes:  [2, 51, 44, 89, 80]\n",
      "[INFO] 10-Jan-26 18:01:43 - Using 8 workers for the dataloader.\n",
      "target classes:  [2, 51, 44, 89, 80]\n",
      "[INFO] 10-Jan-26 18:01:44 - Using 8 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Choose params for task 3: 100%|██████████| 50/50 [00:09<00:00,  5.04it/s, distances=[0.62, 0.64]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load expert 1 parameters\n",
      "Create new expert 3\n",
      "Applying BiLORA technique for current task:  2  at index:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 3 - Epoch 5: 100%|███████████████████████████████████████████████████████████| 390/390 [05:38<00:00,  1.15it/s, loss_ce=0.0148, loss_kd=-1.48, loss_nor=-0.0315, loss_mi=0.092, lr=0.03, ep/h=53.6]\n",
      "Calculate distribution for task 3:  78%|███████▊  | 78/100 [00:14<00:04,  5.28it/s]\n",
      "Choose expert for evaluate: 100%|████████████████████████████████████████████████████████████████████| 45/45 [00:10<00:00,  4.47it/s, task 3=3, distance=[2.9, 2.26, 1.9]]\n",
      "Evaluating:   0%|                                                                                                                                  | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose experts for evaluate: [1, 2, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 1:   7%|██████▌                                                                                           | 3/45 [00:01<00:24,  1.74it/s, acc_task_1=34.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  3  at index:  0\n",
      "Applying BiLORA technique for current task:  3  at index:  0\n",
      "Applying BiLORA technique for current task:  3  at index:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 2:  13%|█████████████▎                                                                                      | 6/45 [00:03<00:23,  1.68it/s, acc_task_2=25]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  3  at index:  1\n",
      "Applying BiLORA technique for current task:  3  at index:  1\n",
      "Applying BiLORA technique for current task:  3  at index:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 3:  20%|███████████████████▌                                                                              | 9/45 [00:05<00:23,  1.56it/s, acc_task_3=92.7]\n",
      "Accuracy for 3 task(s): \t [Class-IL]: 50.69 % \t [Task-IL]: 0.0 %\n",
      "\tRaw accuracy values: Class-IL [34.375, 25.0, 92.70833333333334] | Task-IL [0, 0, 0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "System stats:\n",
      "\tInitial CPU memory usage: 2780.89 MB\n",
      "\tAverage CPU memory usage: 3851.34 MB\n",
      "\tFinal CPU memory usage: 4474.70 MB\n",
      "\tMax CPU memory usage: 4474.70 MB\n",
      "\tInitial GPU 0 memory usage: 1082.00 MB\n",
      "\tAverage GPU 0 memory usage: 6188.00 MB\n",
      "\tFinal GPU 0 memory usage: 6188.00 MB\n",
      "\tMax GPU 0 memory usage: 6188.00 MB\n",
      "Logging results and arguments in ./data/results/class-il/seq-cifar100/LEAR/logs.pyd\n",
      "[INFO CMD] Running:  python main_domain.py --list_datasets seq-cifar100,seq-cifar100,seq-cifar100 --dataset seq-cifar100 --ncls_per_task 5 --model LEAR --lr 0.03 --batch_size 32 --n_epochs 5 --num_workers 8 --backbone lear --transform_type weak --use_bilora 1 --apply_bilora_for local --bilora_mode separate --skip_task_0 1\n",
      "[INFO] 10-Jan-26 18:08:08 - Running Mammoth! on 04dc83e5ff9c. (if you see this message more than once, you are probably importing something wrong)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 10-Jan-26 18:08:11 - NumExpr defaulting to 4 threads.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (4.4.4) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] 10-Jan-26 18:08:12 - Trying to load default configuration for model LEAR but no configuration file found in None.\n",
      "[WARNING] 10-Jan-26 18:08:12 - Default configuration file not found for dataset seq-cifar100. Using the defaults specified in the dataset class (if available).\n",
      "[INFO] 10-Jan-26 18:08:12 - `lr_scheduler` set to multisteplr, overrides default from dataset.\n",
      "[INFO] 10-Jan-26 18:08:12 - Using device cuda:0\n",
      "Loading dataset: seq-cifar100\n",
      "Loading dataset: seq-cifar100\n",
      "Loading dataset: seq-cifar100\n",
      "[INFO] 10-Jan-26 18:08:12 - `wandb_entity` and `wandb_project` not set. Disabling wandb.\n",
      "[WARNING] 10-Jan-26 18:08:12 - Label noise is not available with multi-label datasets. If this is not multi-label, ignore this warning.\n",
      "[INFO] 10-Jan-26 18:08:14 - Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)\n",
      "[INFO] 10-Jan-26 18:08:14 - [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "[INFO] 10-Jan-26 18:08:14 - Missing keys (head.weight, head.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n",
      "[INFO] 10-Jan-26 18:08:15 - Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)\n",
      "[INFO] 10-Jan-26 18:08:16 - [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "[INFO] 10-Jan-26 18:08:16 - Missing keys (head.weight, head.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n",
      "[INFO] 10-Jan-26 18:08:16 - Using backbone: lear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LEAR as backbone\n",
      "Use BiLORA:  True\n",
      "Apply BiLORA for:  local\n",
      "Namespace(dataset='seq-cifar100', model='LEAR', backbone='lear', load_best_args=False, dataset_config=None, model_config='default', list_datasets='seq-cifar100,seq-cifar100,seq-cifar100', transform_type='weak', ncls_per_task=5, use_bilora=1, apply_bilora_for='local', skip_task_0=1, bilora_mode='separate', num_classes=100, seed=None, permute_classes=False, base_path='./data/', results_path='results/', device=device(type='cuda', index=0), notes=None, eval_epochs=None, non_verbose=False, disable_log=False, num_workers=8, enable_other_metrics=False, debug_mode=False, inference_only=False, code_optimization=0, distributed='no', savecheck=None, save_checkpoint_mode='safe', loadcheck=None, ckpt_name=None, start_from=None, stop_after=None, wandb_name=None, wandb_entity=None, wandb_project=None, lr=0.03, batch_size=32, label_perc=1.0, label_perc_by_class=1.0, joint=0, eval_future=False, validation=None, validation_mode='current', fitting_mode='epochs', early_stopping_patience=5, early_stopping_metric='loss', early_stopping_freq=1, early_stopping_epsilon=1e-06, n_epochs=5, n_iters=None, optimizer='sgd', optim_wd=0.0, optim_mom=0.0, optim_nesterov=False, drop_last=False, lr_scheduler='multisteplr', scheduler_mode='epoch', lr_milestones=[35, 45], sched_multistep_lr_gamma=0.1, noise_type='symmetric', noise_rate=0.0, disable_noisy_labels_cache=False, cache_path_noisy_labels='noisy_labels', conf_jobnum='feec348f-a22e-4ee0-a558-b5f143c83506', conf_timestamp='2026-01-10 18:08:12.596705', conf_host='04dc83e5ff9c', conf_git_hash='d9141df2a3954ab461ad96da8cee30a4693fe2d0', minibatch_size=32, nowand=1)\n",
      "begin task 1, dataset:seq-cifar100\n",
      "target classes:  [84, 20, 67, 40, 32]\n",
      "[INFO] 10-Jan-26 18:08:18 - Using 8 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target classes:  [84, 20, 67, 40, 32]\n",
      "[INFO] 10-Jan-26 18:08:19 - Using 8 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 1 - Epoch 5: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 390/390 [03:46<00:00,  1.72it/s, loss_ce=0.0382, loss_nor=-0.0323, lr=0.03, ep/h=79.9]\n",
      "Calculate distribution for task 1:  78%|███████▊  | 78/100 [00:14<00:04,  5.40it/s]\n",
      "Evaluating:   0%|                                                                                                                                  | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose experts for evaluate: [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 1:  20%|███████████████████▌                                                                              | 3/15 [00:01<00:07,  1.60it/s, acc_task_1=97.9]\n",
      "Accuracy for 1 task(s): \t [Class-IL]: 97.92 % \t [Task-IL]: 0.0 %\n",
      "\tRaw accuracy values: Class-IL [97.91666666666666] | Task-IL [0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  1  at index:  0\n",
      "Applying BiLORA technique for current task:  1  at index:  0\n",
      "Applying BiLORA technique for current task:  1  at index:  0\n",
      "begin task 2, dataset:seq-cifar100\n",
      "target classes:  [21, 89, 85, 13, 16]\n",
      "[INFO] 10-Jan-26 18:12:24 - Using 8 workers for the dataloader.\n",
      "target classes:  [21, 89, 85, 13, 16]\n",
      "[INFO] 10-Jan-26 18:12:25 - Using 8 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Choose params for task 2: 100%|██████████| 50/50 [00:09<00:00,  5.09it/s, distances=[1.02]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load expert 1 parameters\n",
      "Create new expert 2\n",
      "Applying BiLORA technique for current task:  1  at index:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 2 - Epoch 5: 100%|█████████████████████████████████████████████████████████████| 390/390 [05:35<00:00,  1.16it/s, loss_ce=3.09, loss_kd=-0.406, loss_nor=-0.0321, loss_mi=3.95, lr=0.03, ep/h=54.4]\n",
      "Calculate distribution for task 2:  78%|███████▊  | 78/100 [00:14<00:04,  5.29it/s]\n",
      "Choose expert for evaluate: 100%|████████████████████████████████████████████████████████████████████████| 30/30 [00:06<00:00,  4.56it/s, task 2=2, distance=[4.01, 1.77]]\n",
      "Evaluating:   0%|                                                                                                                                  | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose experts for evaluate: [2, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 1:  10%|██████████                                                                                           | 3/30 [00:01<00:15,  1.75it/s, acc_task_1=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  2  at index:  1\n",
      "Applying BiLORA technique for current task:  2  at index:  1\n",
      "Applying BiLORA technique for current task:  2  at index:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 2:  20%|███████████████████▌                                                                              | 6/30 [00:03<00:14,  1.60it/s, acc_task_2=47.9]\n",
      "Accuracy for 2 task(s): \t [Class-IL]: 23.96 % \t [Task-IL]: 0.0 %\n",
      "\tRaw accuracy values: Class-IL [0.0, 47.91666666666667] | Task-IL [0, 0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  2  at index:  1\n",
      "Applying BiLORA technique for current task:  2  at index:  1\n",
      "Applying BiLORA technique for current task:  2  at index:  1\n",
      "begin task 3, dataset:seq-cifar100\n",
      "target classes:  [24, 45, 56, 21, 60]\n",
      "[INFO] 10-Jan-26 18:18:39 - Using 8 workers for the dataloader.\n",
      "target classes:  [24, 45, 56, 21, 60]\n",
      "[INFO] 10-Jan-26 18:18:40 - Using 8 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Choose params for task 3: 100%|██████████| 50/50 [00:09<00:00,  5.05it/s, distances=[0.98, 0.64]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load expert 2 parameters\n",
      "Create new expert 3\n",
      "Applying BiLORA technique for current task:  2  at index:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 3 - Epoch 5: 100%|███████████████████████████████████████████████████████████| 390/390 [05:38<00:00,  1.15it/s, loss_ce=0.0475, loss_kd=-2.3, loss_nor=-0.0313, loss_mi=0.0228, lr=0.03, ep/h=53.3]\n",
      "Calculate distribution for task 3:  78%|███████▊  | 78/100 [00:14<00:04,  5.29it/s]\n",
      "Choose expert for evaluate: 100%|██████████████████████████████████████████████████████████████████| 45/45 [00:10<00:00,  4.48it/s, task 3=3, distance=[3.33, 2.11, 1.93]]\n",
      "Evaluating:   0%|                                                                                                                                  | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose experts for evaluate: [2, 2, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 1:   7%|██████▋                                                                                              | 3/45 [00:01<00:24,  1.71it/s, acc_task_1=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  3  at index:  1\n",
      "Applying BiLORA technique for current task:  3  at index:  1\n",
      "Applying BiLORA technique for current task:  3  at index:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 2:  13%|█████████████                                                                                     | 6/45 [00:03<00:23,  1.67it/s, acc_task_2=42.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  3  at index:  1\n",
      "Applying BiLORA technique for current task:  3  at index:  1\n",
      "Applying BiLORA technique for current task:  3  at index:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 3:  20%|███████████████████▌                                                                              | 9/45 [00:05<00:23,  1.56it/s, acc_task_3=95.8]\n",
      "Accuracy for 3 task(s): \t [Class-IL]: 46.18 % \t [Task-IL]: 0.0 %\n",
      "\tRaw accuracy values: Class-IL [0.0, 42.70833333333333, 95.83333333333334] | Task-IL [0, 0, 0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "System stats:\n",
      "\tInitial CPU memory usage: 2648.84 MB\n",
      "\tAverage CPU memory usage: 3627.97 MB\n",
      "\tFinal CPU memory usage: 4209.46 MB\n",
      "\tMax CPU memory usage: 4209.45 MB\n",
      "\tInitial GPU 0 memory usage: 1082.00 MB\n",
      "\tAverage GPU 0 memory usage: 6214.00 MB\n",
      "\tFinal GPU 0 memory usage: 6216.00 MB\n",
      "\tMax GPU 0 memory usage: 6214.00 MB\n",
      "Logging results and arguments in ./data/results/class-il/seq-cifar100/LEAR/logs.pyd\n",
      "[INFO CMD] Running:  python main_domain.py --list_datasets seq-cifar100,seq-cifar100,seq-cifar100 --dataset seq-cifar100 --ncls_per_task 5 --model LEAR --lr 0.03 --batch_size 32 --n_epochs 5 --num_workers 8 --backbone lear --transform_type weak --use_bilora 1 --apply_bilora_for local --bilora_mode aggregate --skip_task_0 0\n",
      "[INFO] 10-Jan-26 18:25:03 - Running Mammoth! on 04dc83e5ff9c. (if you see this message more than once, you are probably importing something wrong)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 10-Jan-26 18:25:06 - NumExpr defaulting to 4 threads.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (4.4.4) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] 10-Jan-26 18:25:07 - Trying to load default configuration for model LEAR but no configuration file found in None.\n",
      "[WARNING] 10-Jan-26 18:25:07 - Default configuration file not found for dataset seq-cifar100. Using the defaults specified in the dataset class (if available).\n",
      "[INFO] 10-Jan-26 18:25:07 - `lr_scheduler` set to multisteplr, overrides default from dataset.\n",
      "[INFO] 10-Jan-26 18:25:07 - Using device cuda:0\n",
      "Loading dataset: seq-cifar100\n",
      "Loading dataset: seq-cifar100\n",
      "Loading dataset: seq-cifar100\n",
      "[INFO] 10-Jan-26 18:25:07 - `wandb_entity` and `wandb_project` not set. Disabling wandb.\n",
      "[WARNING] 10-Jan-26 18:25:07 - Label noise is not available with multi-label datasets. If this is not multi-label, ignore this warning.\n",
      "[INFO] 10-Jan-26 18:25:08 - Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)\n",
      "[INFO] 10-Jan-26 18:25:09 - [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "[INFO] 10-Jan-26 18:25:09 - Missing keys (head.weight, head.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n",
      "[INFO] 10-Jan-26 18:25:10 - Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)\n",
      "[INFO] 10-Jan-26 18:25:10 - [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "[INFO] 10-Jan-26 18:25:10 - Missing keys (head.weight, head.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n",
      "[INFO] 10-Jan-26 18:25:11 - Using backbone: lear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LEAR as backbone\n",
      "Use BiLORA:  True\n",
      "Apply BiLORA for:  local\n",
      "Namespace(dataset='seq-cifar100', model='LEAR', backbone='lear', load_best_args=False, dataset_config=None, model_config='default', list_datasets='seq-cifar100,seq-cifar100,seq-cifar100', transform_type='weak', ncls_per_task=5, use_bilora=1, apply_bilora_for='local', skip_task_0=0, bilora_mode='aggregate', num_classes=100, seed=None, permute_classes=False, base_path='./data/', results_path='results/', device=device(type='cuda', index=0), notes=None, eval_epochs=None, non_verbose=False, disable_log=False, num_workers=8, enable_other_metrics=False, debug_mode=False, inference_only=False, code_optimization=0, distributed='no', savecheck=None, save_checkpoint_mode='safe', loadcheck=None, ckpt_name=None, start_from=None, stop_after=None, wandb_name=None, wandb_entity=None, wandb_project=None, lr=0.03, batch_size=32, label_perc=1.0, label_perc_by_class=1.0, joint=0, eval_future=False, validation=None, validation_mode='current', fitting_mode='epochs', early_stopping_patience=5, early_stopping_metric='loss', early_stopping_freq=1, early_stopping_epsilon=1e-06, n_epochs=5, n_iters=None, optimizer='sgd', optim_wd=0.0, optim_mom=0.0, optim_nesterov=False, drop_last=False, lr_scheduler='multisteplr', scheduler_mode='epoch', lr_milestones=[35, 45], sched_multistep_lr_gamma=0.1, noise_type='symmetric', noise_rate=0.0, disable_noisy_labels_cache=False, cache_path_noisy_labels='noisy_labels', conf_jobnum='9ea32f5c-07ca-4a4b-8340-963c2f75f35c', conf_timestamp='2026-01-10 18:25:07.501368', conf_host='04dc83e5ff9c', conf_git_hash='d9141df2a3954ab461ad96da8cee30a4693fe2d0', minibatch_size=32, nowand=1)\n",
      "begin task 1, dataset:seq-cifar100\n",
      "target classes:  [85, 73, 15, 22, 60]\n",
      "[INFO] 10-Jan-26 18:25:13 - Using 8 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target classes:  [85, 73, 15, 22, 60]\n",
      "[INFO] 10-Jan-26 18:25:14 - Using 8 workers for the dataloader.\n",
      "Applying BiLORA technique for current task:  0  at index:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 1 - Epoch 5: 100%|████████████████████████████████████████████████████████████████████████████████████████| 390/390 [04:59<00:00,  1.30it/s, loss_ce=0.00572, loss_nor=-0.0323, lr=0.03, ep/h=60.4]\n",
      "Calculate distribution for task 1:  78%|███████▊  | 78/100 [00:14<00:04,  5.27it/s]\n",
      "Evaluating:   0%|                                                                                                                                  | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose experts for evaluate: [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 1:  20%|███████████████████▊                                                                               | 3/15 [00:01<00:07,  1.55it/s, acc_task_1=100]\n",
      "Accuracy for 1 task(s): \t [Class-IL]: 100.0 % \t [Task-IL]: 0.0 %\n",
      "\tRaw accuracy values: Class-IL [100.0] | Task-IL [0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  1  at index:  0\n",
      "Applying BiLORA technique for current task:  1  at index:  0\n",
      "Applying BiLORA technique for current task:  1  at index:  0\n",
      "begin task 2, dataset:seq-cifar100\n",
      "target classes:  [99, 63, 87, 3, 18]\n",
      "[INFO] 10-Jan-26 18:30:33 - Using 8 workers for the dataloader.\n",
      "target classes:  [99, 63, 87, 3, 18]\n",
      "[INFO] 10-Jan-26 18:30:34 - Using 8 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Choose params for task 2: 100%|██████████| 50/50 [00:09<00:00,  5.02it/s, distances=[0.65]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load expert 1 parameters\n",
      "Create new expert 2\n",
      "Applying BiLORA technique for current task:  1  at index:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 2 - Epoch 5: 100%|█████████████████████████████████████████████████████████| 390/390 [05:41<00:00,  1.14it/s, loss_ce=0.00494, loss_kd=-3.26, loss_nor=-0.0311, loss_mi=0.0927, lr=0.03, ep/h=53.1]\n",
      "Calculate distribution for task 2:  78%|███████▊  | 78/100 [00:14<00:04,  5.21it/s]\n",
      "Choose expert for evaluate: 100%|████████████████████████████████████████████████████████████████████████| 30/30 [00:06<00:00,  4.47it/s, task 2=2, distance=[1.99, 1.96]]\n",
      "Evaluating:   0%|                                                                                                                                  | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose experts for evaluate: [1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 1:  10%|█████████▉                                                                                         | 3/30 [00:01<00:16,  1.66it/s, acc_task_1=100]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  2  at index:  0\n",
      "Applying BiLORA technique for current task:  2  at index:  0\n",
      "Applying BiLORA technique for current task:  2  at index:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 2:  20%|███████████████████▌                                                                              | 6/30 [00:03<00:15,  1.53it/s, acc_task_2=97.9]\n",
      "Accuracy for 2 task(s): \t [Class-IL]: 98.96 % \t [Task-IL]: 0.0 %\n",
      "\tRaw accuracy values: Class-IL [100.0, 97.91666666666666] | Task-IL [0, 0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  2  at index:  1\n",
      "Applying BiLORA technique for current task:  2  at index:  1\n",
      "Applying BiLORA technique for current task:  2  at index:  1\n",
      "begin task 3, dataset:seq-cifar100\n",
      "target classes:  [7, 43, 57, 92, 97]\n",
      "[INFO] 10-Jan-26 18:36:55 - Using 8 workers for the dataloader.\n",
      "target classes:  [7, 43, 57, 92, 97]\n",
      "[INFO] 10-Jan-26 18:36:55 - Using 8 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Choose params for task 3: 100%|██████████| 50/50 [00:10<00:00,  4.90it/s, distances=[0.69, 1.44]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load expert 1 parameters\n",
      "Create new expert 3\n",
      "Applying BiLORA technique for current task:  2  at index:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 3 - Epoch 5: 100%|█████████████████████████████████████████████████████████| 390/390 [05:46<00:00,  1.13it/s, loss_ce=0.0088, loss_kd=-0.218, loss_nor=-0.0284, loss_mi=0.0562, lr=0.03, ep/h=52.5]\n",
      "Calculate distribution for task 3:  78%|███████▊  | 78/100 [00:15<00:04,  5.13it/s]\n",
      "Choose expert for evaluate: 100%|██████████████████████████████████████████████████████████████████| 45/45 [00:10<00:00,  4.32it/s, task 3=3, distance=[2.24, 2.96, 2.16]]\n",
      "Evaluating:   0%|                                                                                                                                  | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose experts for evaluate: [1, 1, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 1:   7%|██████▌                                                                                            | 3/45 [00:01<00:25,  1.66it/s, acc_task_1=100]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  3  at index:  0\n",
      "Applying BiLORA technique for current task:  3  at index:  0\n",
      "Applying BiLORA technique for current task:  3  at index:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 2:  13%|█████████████▍                                                                                       | 6/45 [00:03<00:24,  1.61it/s, acc_task_2=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  3  at index:  0\n",
      "Applying BiLORA technique for current task:  3  at index:  0\n",
      "Applying BiLORA technique for current task:  3  at index:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 3:  20%|███████████████████▌                                                                              | 9/45 [00:06<00:24,  1.50it/s, acc_task_3=97.9]\n",
      "Accuracy for 3 task(s): \t [Class-IL]: 65.97 % \t [Task-IL]: 0.0 %\n",
      "\tRaw accuracy values: Class-IL [100.0, 0.0, 97.91666666666666] | Task-IL [0, 0, 0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "System stats:\n",
      "\tInitial CPU memory usage: 2648.70 MB\n",
      "\tAverage CPU memory usage: 3622.40 MB\n",
      "\tFinal CPU memory usage: 4270.50 MB\n",
      "\tMax CPU memory usage: 4250.19 MB\n",
      "\tInitial GPU 0 memory usage: 1082.00 MB\n",
      "\tAverage GPU 0 memory usage: 6190.00 MB\n",
      "\tFinal GPU 0 memory usage: 6190.00 MB\n",
      "\tMax GPU 0 memory usage: 6190.00 MB\n",
      "Logging results and arguments in ./data/results/class-il/seq-cifar100/LEAR/logs.pyd\n",
      "[INFO CMD] Running:  python main_domain.py --list_datasets seq-cifar100,seq-cifar100,seq-cifar100 --dataset seq-cifar100 --ncls_per_task 5 --model LEAR --lr 0.03 --batch_size 32 --n_epochs 5 --num_workers 8 --backbone lear --transform_type weak --use_bilora 1 --apply_bilora_for local --bilora_mode aggregate --skip_task_0 1\n",
      "[INFO] 10-Jan-26 18:43:27 - Running Mammoth! on 04dc83e5ff9c. (if you see this message more than once, you are probably importing something wrong)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 10-Jan-26 18:43:31 - NumExpr defaulting to 4 threads.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (4.4.4) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] 10-Jan-26 18:43:32 - Trying to load default configuration for model LEAR but no configuration file found in None.\n",
      "[WARNING] 10-Jan-26 18:43:32 - Default configuration file not found for dataset seq-cifar100. Using the defaults specified in the dataset class (if available).\n",
      "[INFO] 10-Jan-26 18:43:32 - `lr_scheduler` set to multisteplr, overrides default from dataset.\n",
      "[INFO] 10-Jan-26 18:43:32 - Using device cuda:0\n",
      "Loading dataset: seq-cifar100\n",
      "Loading dataset: seq-cifar100\n",
      "Loading dataset: seq-cifar100\n",
      "[INFO] 10-Jan-26 18:43:32 - `wandb_entity` and `wandb_project` not set. Disabling wandb.\n",
      "[WARNING] 10-Jan-26 18:43:32 - Label noise is not available with multi-label datasets. If this is not multi-label, ignore this warning.\n",
      "[INFO] 10-Jan-26 18:43:33 - Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)\n",
      "[INFO] 10-Jan-26 18:43:33 - [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "[INFO] 10-Jan-26 18:43:33 - Missing keys (head.weight, head.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n",
      "[INFO] 10-Jan-26 18:43:35 - Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)\n",
      "[INFO] 10-Jan-26 18:43:35 - [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "[INFO] 10-Jan-26 18:43:35 - Missing keys (head.weight, head.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n",
      "[INFO] 10-Jan-26 18:43:35 - Using backbone: lear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LEAR as backbone\n",
      "Use BiLORA:  True\n",
      "Apply BiLORA for:  local\n",
      "Namespace(dataset='seq-cifar100', model='LEAR', backbone='lear', load_best_args=False, dataset_config=None, model_config='default', list_datasets='seq-cifar100,seq-cifar100,seq-cifar100', transform_type='weak', ncls_per_task=5, use_bilora=1, apply_bilora_for='local', skip_task_0=1, bilora_mode='aggregate', num_classes=100, seed=None, permute_classes=False, base_path='./data/', results_path='results/', device=device(type='cuda', index=0), notes=None, eval_epochs=None, non_verbose=False, disable_log=False, num_workers=8, enable_other_metrics=False, debug_mode=False, inference_only=False, code_optimization=0, distributed='no', savecheck=None, save_checkpoint_mode='safe', loadcheck=None, ckpt_name=None, start_from=None, stop_after=None, wandb_name=None, wandb_entity=None, wandb_project=None, lr=0.03, batch_size=32, label_perc=1.0, label_perc_by_class=1.0, joint=0, eval_future=False, validation=None, validation_mode='current', fitting_mode='epochs', early_stopping_patience=5, early_stopping_metric='loss', early_stopping_freq=1, early_stopping_epsilon=1e-06, n_epochs=5, n_iters=None, optimizer='sgd', optim_wd=0.0, optim_mom=0.0, optim_nesterov=False, drop_last=False, lr_scheduler='multisteplr', scheduler_mode='epoch', lr_milestones=[35, 45], sched_multistep_lr_gamma=0.1, noise_type='symmetric', noise_rate=0.0, disable_noisy_labels_cache=False, cache_path_noisy_labels='noisy_labels', conf_jobnum='0b4db1e7-e139-464c-8325-5d75ac79e7aa', conf_timestamp='2026-01-10 18:43:32.198409', conf_host='04dc83e5ff9c', conf_git_hash='d9141df2a3954ab461ad96da8cee30a4693fe2d0', minibatch_size=32, nowand=1)\n",
      "begin task 1, dataset:seq-cifar100\n",
      "target classes:  [32, 63, 6, 93, 57]\n",
      "[INFO] 10-Jan-26 18:43:38 - Using 8 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target classes:  [32, 63, 6, 93, 57]\n",
      "[INFO] 10-Jan-26 18:43:39 - Using 8 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 1 - Epoch 5: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 390/390 [03:45<00:00,  1.73it/s, loss_ce=0.0025, loss_nor=-0.0323, lr=0.03, ep/h=80.6]\n",
      "Calculate distribution for task 1:  78%|███████▊  | 78/100 [00:14<00:04,  5.43it/s]\n",
      "Evaluating:   0%|                                                                                                                                  | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose experts for evaluate: [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 1:  20%|███████████████████▌                                                                              | 3/15 [00:01<00:07,  1.58it/s, acc_task_1=95.8]\n",
      "Accuracy for 1 task(s): \t [Class-IL]: 95.83 % \t [Task-IL]: 0.0 %\n",
      "\tRaw accuracy values: Class-IL [95.83333333333334] | Task-IL [0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  1  at index:  0\n",
      "Applying BiLORA technique for current task:  1  at index:  0\n",
      "Applying BiLORA technique for current task:  1  at index:  0\n",
      "begin task 2, dataset:seq-cifar100\n",
      "target classes:  [92, 65, 66, 40, 46]\n",
      "[INFO] 10-Jan-26 18:47:43 - Using 8 workers for the dataloader.\n",
      "target classes:  [92, 65, 66, 40, 46]\n",
      "[INFO] 10-Jan-26 18:47:44 - Using 8 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Choose params for task 2: 100%|██████████| 50/50 [00:09<00:00,  5.01it/s, distances=[0.97]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load expert 1 parameters\n",
      "Create new expert 2\n",
      "Applying BiLORA technique for current task:  1  at index:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 2 - Epoch 5: 100%|██████████████████████████████████████████████████████████████| 390/390 [05:38<00:00,  1.15it/s, loss_ce=1.82, loss_kd=-1.58, loss_nor=-0.0323, loss_mi=3.06, lr=0.03, ep/h=53.8]\n",
      "Calculate distribution for task 2:  78%|███████▊  | 78/100 [00:15<00:04,  5.20it/s]\n",
      "Choose expert for evaluate: 100%|█████████████████████████████████████████████████████████████████████████| 30/30 [00:06<00:00,  4.42it/s, task 2=2, distance=[3.7, 2.11]]\n",
      "Evaluating:   0%|                                                                                                                                  | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose experts for evaluate: [2, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 1:  10%|██████████                                                                                           | 3/30 [00:01<00:16,  1.64it/s, acc_task_1=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  2  at index:  1\n",
      "Applying BiLORA technique for current task:  2  at index:  1\n",
      "Applying BiLORA technique for current task:  2  at index:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 2:  20%|████████████████████                                                                                | 6/30 [00:03<00:15,  1.51it/s, acc_task_2=76]\n",
      "Accuracy for 2 task(s): \t [Class-IL]: 38.02 % \t [Task-IL]: 0.0 %\n",
      "\tRaw accuracy values: Class-IL [0.0, 76.04166666666666] | Task-IL [0, 0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  2  at index:  1\n",
      "Applying BiLORA technique for current task:  2  at index:  1\n",
      "Applying BiLORA technique for current task:  2  at index:  1\n",
      "begin task 3, dataset:seq-cifar100\n",
      "target classes:  [91, 50, 1, 42, 74]\n",
      "[INFO] 10-Jan-26 18:54:01 - Using 8 workers for the dataloader.\n",
      "target classes:  [91, 50, 1, 42, 74]\n",
      "[INFO] 10-Jan-26 18:54:02 - Using 8 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Choose params for task 3: 100%|██████████| 50/50 [00:10<00:00,  4.90it/s, distances=[0.84, 0.75]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load expert 2 parameters\n",
      "Create new expert 3\n",
      "Applying BiLORA technique for current task:  2  at index:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 3 - Epoch 5: 100%|████████████████████████████████████████████████████████████| 390/390 [05:45<00:00,  1.13it/s, loss_ce=0.747, loss_kd=-1.75, loss_nor=-0.0285, loss_mi=0.187, lr=0.03, ep/h=52.3]\n",
      "Calculate distribution for task 3:  78%|███████▊  | 78/100 [00:15<00:04,  5.16it/s]\n",
      "Choose expert for evaluate: 100%|██████████████████████████████████████████████████████████████████| 45/45 [00:10<00:00,  4.40it/s, task 3=3, distance=[6.76, 5.27, 2.06]]\n",
      "Evaluating:   0%|                                                                                                                                  | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose experts for evaluate: [3, 3, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 1:   7%|██████▋                                                                                              | 3/45 [00:01<00:25,  1.64it/s, acc_task_1=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "Applying BiLORA technique for current task:  3  at index:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 2:  13%|█████████████▍                                                                                       | 6/45 [00:03<00:24,  1.61it/s, acc_task_2=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "Applying BiLORA technique for current task:  3  at index:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 3:  20%|███████████████████▌                                                                              | 9/45 [00:06<00:24,  1.48it/s, acc_task_3=90.6]\n",
      "Accuracy for 3 task(s): \t [Class-IL]: 30.21 % \t [Task-IL]: 0.0 %\n",
      "\tRaw accuracy values: Class-IL [0.0, 0.0, 90.625] | Task-IL [0, 0, 0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "System stats:\n",
      "\tInitial CPU memory usage: 2648.71 MB\n",
      "\tAverage CPU memory usage: 3660.61 MB\n",
      "\tFinal CPU memory usage: 4303.38 MB\n",
      "\tMax CPU memory usage: 4287.42 MB\n",
      "\tInitial GPU 0 memory usage: 1082.00 MB\n",
      "\tAverage GPU 0 memory usage: 6214.00 MB\n",
      "\tFinal GPU 0 memory usage: 6216.00 MB\n",
      "\tMax GPU 0 memory usage: 6214.00 MB\n",
      "Logging results and arguments in ./data/results/class-il/seq-cifar100/LEAR/logs.pyd\n",
      "[INFO CMD] Running:  python main_domain.py --list_datasets seq-cifar100,seq-cifar100,seq-cifar100 --dataset seq-cifar100 --ncls_per_task 5 --model LEAR --lr 0.03 --batch_size 32 --n_epochs 5 --num_workers 8 --backbone lear --transform_type weak --use_bilora 1 --apply_bilora_for both --bilora_mode separate --skip_task_0 0\n",
      "[INFO] 10-Jan-26 19:00:33 - Running Mammoth! on 04dc83e5ff9c. (if you see this message more than once, you are probably importing something wrong)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 10-Jan-26 19:00:36 - NumExpr defaulting to 4 threads.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (4.4.4) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] 10-Jan-26 19:00:37 - Trying to load default configuration for model LEAR but no configuration file found in None.\n",
      "[WARNING] 10-Jan-26 19:00:37 - Default configuration file not found for dataset seq-cifar100. Using the defaults specified in the dataset class (if available).\n",
      "[INFO] 10-Jan-26 19:00:37 - `lr_scheduler` set to multisteplr, overrides default from dataset.\n",
      "[INFO] 10-Jan-26 19:00:37 - Using device cuda:0\n",
      "Loading dataset: seq-cifar100\n",
      "Loading dataset: seq-cifar100\n",
      "Loading dataset: seq-cifar100\n",
      "[INFO] 10-Jan-26 19:00:37 - `wandb_entity` and `wandb_project` not set. Disabling wandb.\n",
      "[WARNING] 10-Jan-26 19:00:37 - Label noise is not available with multi-label datasets. If this is not multi-label, ignore this warning.\n",
      "[INFO] 10-Jan-26 19:00:39 - Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)\n",
      "[INFO] 10-Jan-26 19:00:39 - [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "[INFO] 10-Jan-26 19:00:39 - Missing keys (head.weight, head.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n",
      "[INFO] 10-Jan-26 19:00:41 - Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)\n",
      "[INFO] 10-Jan-26 19:00:41 - [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "[INFO] 10-Jan-26 19:00:41 - Missing keys (head.weight, head.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n",
      "[INFO] 10-Jan-26 19:00:41 - Using backbone: lear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LEAR as backbone\n",
      "Use BiLORA:  True\n",
      "Apply BiLORA for:  both\n",
      "Namespace(dataset='seq-cifar100', model='LEAR', backbone='lear', load_best_args=False, dataset_config=None, model_config='default', list_datasets='seq-cifar100,seq-cifar100,seq-cifar100', transform_type='weak', ncls_per_task=5, use_bilora=1, apply_bilora_for='both', skip_task_0=0, bilora_mode='separate', num_classes=100, seed=None, permute_classes=False, base_path='./data/', results_path='results/', device=device(type='cuda', index=0), notes=None, eval_epochs=None, non_verbose=False, disable_log=False, num_workers=8, enable_other_metrics=False, debug_mode=False, inference_only=False, code_optimization=0, distributed='no', savecheck=None, save_checkpoint_mode='safe', loadcheck=None, ckpt_name=None, start_from=None, stop_after=None, wandb_name=None, wandb_entity=None, wandb_project=None, lr=0.03, batch_size=32, label_perc=1.0, label_perc_by_class=1.0, joint=0, eval_future=False, validation=None, validation_mode='current', fitting_mode='epochs', early_stopping_patience=5, early_stopping_metric='loss', early_stopping_freq=1, early_stopping_epsilon=1e-06, n_epochs=5, n_iters=None, optimizer='sgd', optim_wd=0.0, optim_mom=0.0, optim_nesterov=False, drop_last=False, lr_scheduler='multisteplr', scheduler_mode='epoch', lr_milestones=[35, 45], sched_multistep_lr_gamma=0.1, noise_type='symmetric', noise_rate=0.0, disable_noisy_labels_cache=False, cache_path_noisy_labels='noisy_labels', conf_jobnum='8164b375-0a90-4781-b1af-8650ff9eccc3', conf_timestamp='2026-01-10 19:00:37.855908', conf_host='04dc83e5ff9c', conf_git_hash='d9141df2a3954ab461ad96da8cee30a4693fe2d0', minibatch_size=32, nowand=1)\n",
      "begin task 1, dataset:seq-cifar100\n",
      "target classes:  [86, 13, 36, 97, 28]\n",
      "[INFO] 10-Jan-26 19:00:44 - Using 8 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target classes:  [86, 13, 36, 97, 28]\n",
      "[INFO] 10-Jan-26 19:00:45 - Using 8 workers for the dataloader.\n",
      "Applying BiLORA technique for current task:  0  at index:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 1 - Epoch 5: 100%|████████████████████████████████████████████████████████████████████████████████████████| 390/390 [06:12<00:00,  1.05it/s, loss_ce=0.00176, loss_nor=-0.0322, lr=0.03, ep/h=48.6]\n",
      "Calculate distribution for task 1:  78%|███████▊  | 78/100 [00:14<00:04,  5.27it/s]\n",
      "Evaluating:   0%|                                                                                                                                  | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose experts for evaluate: [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 1:  20%|███████████████████▌                                                                              | 3/15 [00:02<00:08,  1.35it/s, acc_task_1=47.9]\n",
      "Accuracy for 1 task(s): \t [Class-IL]: 47.92 % \t [Task-IL]: 0.0 %\n",
      "\tRaw accuracy values: Class-IL [47.91666666666667] | Task-IL [0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  1  at index:  0\n",
      "Applying BiLORA technique for current task:  1  at index:  0\n",
      "Applying BiLORA technique for current task:  1  at index:  0\n",
      "begin task 2, dataset:seq-cifar100\n",
      "target classes:  [38, 61, 92, 65, 47]\n",
      "[INFO] 10-Jan-26 19:07:17 - Using 8 workers for the dataloader.\n",
      "target classes:  [38, 61, 92, 65, 47]\n",
      "[INFO] 10-Jan-26 19:07:18 - Using 8 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Choose params for task 2: 100%|██████████| 50/50 [00:09<00:00,  5.10it/s, distances=[0.84]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load expert 1 parameters\n",
      "Create new expert 2\n",
      "Applying BiLORA technique for current task:  1  at index:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 2 - Epoch 5: 100%|███████████████████████████████████████████████████████████| 390/390 [07:16<00:00,  1.12s/it, loss_ce=0.108, loss_kd=-2.91, loss_nor=-0.0301, loss_mi=0.0731, lr=0.03, ep/h=41.3]\n",
      "Calculate distribution for task 2:  78%|███████▊  | 78/100 [00:14<00:04,  5.29it/s]\n",
      "Choose expert for evaluate: 100%|█████████████████████████████████████████████████████████████████████████| 30/30 [00:06<00:00,  4.53it/s, task 2=2, distance=[3.0, 1.84]]\n",
      "Evaluating:   0%|                                                                                                                                  | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose experts for evaluate: [1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 1:  10%|█████████▊                                                                                        | 3/30 [00:02<00:18,  1.43it/s, acc_task_1=18.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  2  at index:  0\n",
      "Applying BiLORA technique for current task:  2  at index:  0\n",
      "Applying BiLORA technique for current task:  2  at index:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 2:  20%|███████████████████▌                                                                              | 6/30 [00:04<00:18,  1.30it/s, acc_task_2=89.6]\n",
      "Accuracy for 2 task(s): \t [Class-IL]: 54.17 % \t [Task-IL]: 0.0 %\n",
      "\tRaw accuracy values: Class-IL [18.75, 89.58333333333334] | Task-IL [0, 0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  2  at index:  1\n",
      "Applying BiLORA technique for current task:  2  at index:  1\n",
      "Applying BiLORA technique for current task:  2  at index:  1\n",
      "begin task 3, dataset:seq-cifar100\n",
      "target classes:  [72, 99, 53, 11, 70]\n",
      "[INFO] 10-Jan-26 19:15:13 - Using 8 workers for the dataloader.\n",
      "target classes:  [72, 99, 53, 11, 70]\n",
      "[INFO] 10-Jan-26 19:15:14 - Using 8 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Choose params for task 3: 100%|██████████| 50/50 [00:09<00:00,  5.03it/s, distances=[0.94, 0.79]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load expert 2 parameters\n",
      "Create new expert 3\n",
      "Applying BiLORA technique for current task:  2  at index:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 3 - Epoch 5: 100%|█████████████████████████████████████████████████████████| 390/390 [07:16<00:00,  1.12s/it, loss_ce=0.0602, loss_kd=-0.241, loss_nor=-0.0323, loss_mi=0.0044, lr=0.03, ep/h=41.4]\n",
      "Calculate distribution for task 3:  78%|███████▊  | 78/100 [00:14<00:04,  5.28it/s]\n",
      "Choose expert for evaluate: 100%|██████████████████████████████████████████████████████████████████| 45/45 [00:10<00:00,  4.41it/s, task 3=3, distance=[3.13, 2.43, 1.87]]\n",
      "Evaluating:   0%|                                                                                                                                  | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose experts for evaluate: [1, 2, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 1:   7%|██████▌                                                                                           | 3/45 [00:02<00:30,  1.38it/s, acc_task_1=16.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  3  at index:  0\n",
      "Applying BiLORA technique for current task:  3  at index:  0\n",
      "Applying BiLORA technique for current task:  3  at index:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 2:  13%|█████████████                                                                                     | 6/45 [00:05<00:33,  1.16it/s, acc_task_2=82.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  3  at index:  1\n",
      "Applying BiLORA technique for current task:  3  at index:  1\n",
      "Applying BiLORA technique for current task:  3  at index:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 3:  20%|███████████████████▌                                                                              | 9/45 [00:07<00:30,  1.19it/s, acc_task_3=80.2]\n",
      "Accuracy for 3 task(s): \t [Class-IL]: 59.72 % \t [Task-IL]: 0.0 %\n",
      "\tRaw accuracy values: Class-IL [16.666666666666664, 82.29166666666666, 80.20833333333334] | Task-IL [0, 0, 0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "System stats:\n",
      "\tInitial CPU memory usage: 2649.64 MB\n",
      "\tAverage CPU memory usage: 3789.96 MB\n",
      "\tFinal CPU memory usage: 4528.64 MB\n",
      "\tMax CPU memory usage: 4528.64 MB\n",
      "\tInitial GPU 0 memory usage: 1084.00 MB\n",
      "\tAverage GPU 0 memory usage: 8934.00 MB\n",
      "\tFinal GPU 0 memory usage: 8934.00 MB\n",
      "\tMax GPU 0 memory usage: 8934.00 MB\n",
      "Logging results and arguments in ./data/results/class-il/seq-cifar100/LEAR/logs.pyd\n",
      "[INFO CMD] Running:  python main_domain.py --list_datasets seq-cifar100,seq-cifar100,seq-cifar100 --dataset seq-cifar100 --ncls_per_task 5 --model LEAR --lr 0.03 --batch_size 32 --n_epochs 5 --num_workers 8 --backbone lear --transform_type weak --use_bilora 1 --apply_bilora_for both --bilora_mode separate --skip_task_0 1\n",
      "[INFO] 10-Jan-26 19:23:17 - Running Mammoth! on 04dc83e5ff9c. (if you see this message more than once, you are probably importing something wrong)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 10-Jan-26 19:23:20 - NumExpr defaulting to 4 threads.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (4.4.4) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] 10-Jan-26 19:23:21 - Trying to load default configuration for model LEAR but no configuration file found in None.\n",
      "[WARNING] 10-Jan-26 19:23:21 - Default configuration file not found for dataset seq-cifar100. Using the defaults specified in the dataset class (if available).\n",
      "[INFO] 10-Jan-26 19:23:21 - `lr_scheduler` set to multisteplr, overrides default from dataset.\n",
      "[INFO] 10-Jan-26 19:23:22 - Using device cuda:0\n",
      "Loading dataset: seq-cifar100\n",
      "Loading dataset: seq-cifar100\n",
      "Loading dataset: seq-cifar100\n",
      "[INFO] 10-Jan-26 19:23:22 - `wandb_entity` and `wandb_project` not set. Disabling wandb.\n",
      "[WARNING] 10-Jan-26 19:23:22 - Label noise is not available with multi-label datasets. If this is not multi-label, ignore this warning.\n",
      "[INFO] 10-Jan-26 19:23:23 - Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)\n",
      "[INFO] 10-Jan-26 19:23:23 - [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "[INFO] 10-Jan-26 19:23:23 - Missing keys (head.weight, head.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n",
      "[INFO] 10-Jan-26 19:23:25 - Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)\n",
      "[INFO] 10-Jan-26 19:23:25 - [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "[INFO] 10-Jan-26 19:23:25 - Missing keys (head.weight, head.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n",
      "[INFO] 10-Jan-26 19:23:25 - Using backbone: lear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LEAR as backbone\n",
      "Use BiLORA:  True\n",
      "Apply BiLORA for:  both\n",
      "Namespace(dataset='seq-cifar100', model='LEAR', backbone='lear', load_best_args=False, dataset_config=None, model_config='default', list_datasets='seq-cifar100,seq-cifar100,seq-cifar100', transform_type='weak', ncls_per_task=5, use_bilora=1, apply_bilora_for='both', skip_task_0=1, bilora_mode='separate', num_classes=100, seed=None, permute_classes=False, base_path='./data/', results_path='results/', device=device(type='cuda', index=0), notes=None, eval_epochs=None, non_verbose=False, disable_log=False, num_workers=8, enable_other_metrics=False, debug_mode=False, inference_only=False, code_optimization=0, distributed='no', savecheck=None, save_checkpoint_mode='safe', loadcheck=None, ckpt_name=None, start_from=None, stop_after=None, wandb_name=None, wandb_entity=None, wandb_project=None, lr=0.03, batch_size=32, label_perc=1.0, label_perc_by_class=1.0, joint=0, eval_future=False, validation=None, validation_mode='current', fitting_mode='epochs', early_stopping_patience=5, early_stopping_metric='loss', early_stopping_freq=1, early_stopping_epsilon=1e-06, n_epochs=5, n_iters=None, optimizer='sgd', optim_wd=0.0, optim_mom=0.0, optim_nesterov=False, drop_last=False, lr_scheduler='multisteplr', scheduler_mode='epoch', lr_milestones=[35, 45], sched_multistep_lr_gamma=0.1, noise_type='symmetric', noise_rate=0.0, disable_noisy_labels_cache=False, cache_path_noisy_labels='noisy_labels', conf_jobnum='bfb4ce0f-62bd-4b74-8eaa-72606238c24c', conf_timestamp='2026-01-10 19:23:21.994565', conf_host='04dc83e5ff9c', conf_git_hash='d9141df2a3954ab461ad96da8cee30a4693fe2d0', minibatch_size=32, nowand=1)\n",
      "begin task 1, dataset:seq-cifar100\n",
      "target classes:  [81, 58, 70, 83, 60]\n",
      "[INFO] 10-Jan-26 19:23:28 - Using 8 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target classes:  [81, 58, 70, 83, 60]\n",
      "[INFO] 10-Jan-26 19:23:29 - Using 8 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 1 - Epoch 5: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 390/390 [03:45<00:00,  1.73it/s, loss_ce=0.00037, loss_nor=-0.0323, lr=0.03, ep/h=81]\n",
      "Calculate distribution for task 1:  78%|███████▊  | 78/100 [00:14<00:04,  5.43it/s]\n",
      "Evaluating:   0%|                                                                                                                                  | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose experts for evaluate: [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 1:  20%|████████████████████                                                                                | 3/15 [00:02<00:09,  1.31it/s, acc_task_1=49]\n",
      "Accuracy for 1 task(s): \t [Class-IL]: 48.96 % \t [Task-IL]: 0.0 %\n",
      "\tRaw accuracy values: Class-IL [48.95833333333333] | Task-IL [0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  1  at index:  0\n",
      "Applying BiLORA technique for current task:  1  at index:  0\n",
      "Applying BiLORA technique for current task:  1  at index:  0\n",
      "begin task 2, dataset:seq-cifar100\n",
      "target classes:  [82, 13, 34, 10, 5]\n",
      "[INFO] 10-Jan-26 19:27:34 - Using 8 workers for the dataloader.\n",
      "target classes:  [82, 13, 34, 10, 5]\n",
      "[INFO] 10-Jan-26 19:27:35 - Using 8 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Choose params for task 2: 100%|██████████| 50/50 [00:09<00:00,  5.10it/s, distances=[1.04]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load expert 1 parameters\n",
      "Create new expert 2\n",
      "Applying BiLORA technique for current task:  1  at index:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 2 - Epoch 5: 100%|███████████████████████████████████████████████████████████| 390/390 [07:09<00:00,  1.10s/it, loss_ce=0.115, loss_kd=-2.94, loss_nor=-0.00586, loss_mi=0.026, lr=0.03, ep/h=42.2]\n",
      "Calculate distribution for task 2:  78%|███████▊  | 78/100 [00:14<00:04,  5.29it/s]\n",
      "Choose expert for evaluate: 100%|████████████████████████████████████████████████████████████████████████| 30/30 [00:06<00:00,  4.55it/s, task 2=2, distance=[4.85, 1.77]]\n",
      "Evaluating:   0%|                                                                                                                                  | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose experts for evaluate: [2, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 1:  10%|██████████                                                                                           | 3/30 [00:02<00:18,  1.45it/s, acc_task_1=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  2  at index:  1\n",
      "Applying BiLORA technique for current task:  2  at index:  1\n",
      "Applying BiLORA technique for current task:  2  at index:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 2:  20%|███████████████████▌                                                                              | 6/30 [00:04<00:18,  1.30it/s, acc_task_2=94.8]\n",
      "Accuracy for 2 task(s): \t [Class-IL]: 47.4 % \t [Task-IL]: 0.0 %\n",
      "\tRaw accuracy values: Class-IL [0.0, 94.79166666666666] | Task-IL [0, 0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  2  at index:  1\n",
      "Applying BiLORA technique for current task:  2  at index:  1\n",
      "Applying BiLORA technique for current task:  2  at index:  1\n",
      "begin task 3, dataset:seq-cifar100\n",
      "target classes:  [46, 73, 26, 69, 77]\n",
      "[INFO] 10-Jan-26 19:35:23 - Using 8 workers for the dataloader.\n",
      "target classes:  [46, 73, 26, 69, 77]\n",
      "[INFO] 10-Jan-26 19:35:25 - Using 8 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Choose params for task 3: 100%|██████████| 50/50 [00:09<00:00,  5.02it/s, distances=[1.05, 0.54]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load expert 2 parameters\n",
      "Create new expert 3\n",
      "Applying BiLORA technique for current task:  2  at index:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 3 - Epoch 5: 100%|███████████████████████████████████████████████████████████| 390/390 [07:16<00:00,  1.12s/it, loss_ce=0.421, loss_kd=-0.45, loss_nor=-0.0309, loss_mi=0.0147, lr=0.03, ep/h=41.6]\n",
      "Calculate distribution for task 3:  78%|███████▊  | 78/100 [00:14<00:04,  5.29it/s]\n",
      "Choose expert for evaluate: 100%|███████████████████████████████████████████████████████████████████| 45/45 [00:10<00:00,  4.47it/s, task 3=3, distance=[3.4, 1.95, 1.71]]\n",
      "Evaluating:   0%|                                                                                                                                  | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose experts for evaluate: [2, 2, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 1:   7%|██████▋                                                                                              | 3/45 [00:02<00:29,  1.43it/s, acc_task_1=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  3  at index:  1\n",
      "Applying BiLORA technique for current task:  3  at index:  1\n",
      "Applying BiLORA technique for current task:  3  at index:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 2:  13%|█████████████                                                                                     | 6/45 [00:04<00:28,  1.37it/s, acc_task_2=94.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  3  at index:  1\n",
      "Applying BiLORA technique for current task:  3  at index:  1\n",
      "Applying BiLORA technique for current task:  3  at index:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 3:  20%|████████████████████                                                                                | 9/45 [00:07<00:29,  1.23it/s, acc_task_3=74]\n",
      "Accuracy for 3 task(s): \t [Class-IL]: 56.25 % \t [Task-IL]: 0.0 %\n",
      "\tRaw accuracy values: Class-IL [0.0, 94.79166666666666, 73.95833333333334] | Task-IL [0, 0, 0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "System stats:\n",
      "\tInitial CPU memory usage: 2647.53 MB\n",
      "\tAverage CPU memory usage: 3709.07 MB\n",
      "\tFinal CPU memory usage: 4417.75 MB\n",
      "\tMax CPU memory usage: 4399.53 MB\n",
      "\tInitial GPU 0 memory usage: 1084.00 MB\n",
      "\tAverage GPU 0 memory usage: 8888.00 MB\n",
      "\tFinal GPU 0 memory usage: 8888.00 MB\n",
      "\tMax GPU 0 memory usage: 8888.00 MB\n",
      "Logging results and arguments in ./data/results/class-il/seq-cifar100/LEAR/logs.pyd\n",
      "[INFO CMD] Running:  python main_domain.py --list_datasets seq-cifar100,seq-cifar100,seq-cifar100 --dataset seq-cifar100 --ncls_per_task 5 --model LEAR --lr 0.03 --batch_size 32 --n_epochs 5 --num_workers 8 --backbone lear --transform_type weak --use_bilora 1 --apply_bilora_for both --bilora_mode aggregate --skip_task_0 0\n",
      "[INFO] 10-Jan-26 19:43:27 - Running Mammoth! on 04dc83e5ff9c. (if you see this message more than once, you are probably importing something wrong)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 10-Jan-26 19:43:30 - NumExpr defaulting to 4 threads.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (4.4.4) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] 10-Jan-26 19:43:31 - Trying to load default configuration for model LEAR but no configuration file found in None.\n",
      "[WARNING] 10-Jan-26 19:43:31 - Default configuration file not found for dataset seq-cifar100. Using the defaults specified in the dataset class (if available).\n",
      "[INFO] 10-Jan-26 19:43:31 - `lr_scheduler` set to multisteplr, overrides default from dataset.\n",
      "[INFO] 10-Jan-26 19:43:31 - Using device cuda:0\n",
      "Loading dataset: seq-cifar100\n",
      "Loading dataset: seq-cifar100\n",
      "Loading dataset: seq-cifar100\n",
      "[INFO] 10-Jan-26 19:43:31 - `wandb_entity` and `wandb_project` not set. Disabling wandb.\n",
      "[WARNING] 10-Jan-26 19:43:31 - Label noise is not available with multi-label datasets. If this is not multi-label, ignore this warning.\n",
      "[INFO] 10-Jan-26 19:43:33 - Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)\n",
      "[INFO] 10-Jan-26 19:43:33 - [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "[INFO] 10-Jan-26 19:43:33 - Missing keys (head.weight, head.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n",
      "[INFO] 10-Jan-26 19:43:35 - Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)\n",
      "[INFO] 10-Jan-26 19:43:35 - [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "[INFO] 10-Jan-26 19:43:35 - Missing keys (head.weight, head.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n",
      "[INFO] 10-Jan-26 19:43:35 - Using backbone: lear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LEAR as backbone\n",
      "Use BiLORA:  True\n",
      "Apply BiLORA for:  both\n",
      "Namespace(dataset='seq-cifar100', model='LEAR', backbone='lear', load_best_args=False, dataset_config=None, model_config='default', list_datasets='seq-cifar100,seq-cifar100,seq-cifar100', transform_type='weak', ncls_per_task=5, use_bilora=1, apply_bilora_for='both', skip_task_0=0, bilora_mode='aggregate', num_classes=100, seed=None, permute_classes=False, base_path='./data/', results_path='results/', device=device(type='cuda', index=0), notes=None, eval_epochs=None, non_verbose=False, disable_log=False, num_workers=8, enable_other_metrics=False, debug_mode=False, inference_only=False, code_optimization=0, distributed='no', savecheck=None, save_checkpoint_mode='safe', loadcheck=None, ckpt_name=None, start_from=None, stop_after=None, wandb_name=None, wandb_entity=None, wandb_project=None, lr=0.03, batch_size=32, label_perc=1.0, label_perc_by_class=1.0, joint=0, eval_future=False, validation=None, validation_mode='current', fitting_mode='epochs', early_stopping_patience=5, early_stopping_metric='loss', early_stopping_freq=1, early_stopping_epsilon=1e-06, n_epochs=5, n_iters=None, optimizer='sgd', optim_wd=0.0, optim_mom=0.0, optim_nesterov=False, drop_last=False, lr_scheduler='multisteplr', scheduler_mode='epoch', lr_milestones=[35, 45], sched_multistep_lr_gamma=0.1, noise_type='symmetric', noise_rate=0.0, disable_noisy_labels_cache=False, cache_path_noisy_labels='noisy_labels', conf_jobnum='18b56e7c-22e5-46f9-bd98-99513a079d07', conf_timestamp='2026-01-10 19:43:31.871537', conf_host='04dc83e5ff9c', conf_git_hash='d9141df2a3954ab461ad96da8cee30a4693fe2d0', minibatch_size=32, nowand=1)\n",
      "begin task 1, dataset:seq-cifar100\n",
      "target classes:  [50, 22, 6, 67, 19]\n",
      "[INFO] 10-Jan-26 19:43:38 - Using 8 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target classes:  [50, 22, 6, 67, 19]\n",
      "[INFO] 10-Jan-26 19:43:39 - Using 8 workers for the dataloader.\n",
      "Applying BiLORA technique for current task:  0  at index:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 1 - Epoch 5: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 390/390 [06:12<00:00,  1.05it/s, loss_ce=0.0081, loss_nor=-0.0323, lr=0.03, ep/h=48.7]\n",
      "Calculate distribution for task 1:  78%|███████▊  | 78/100 [00:14<00:04,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose experts for evaluate: [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 1:  20%|███████████████████▌                                                                              | 3/15 [00:02<00:09,  1.31it/s, acc_task_1=56.2]\n",
      "Accuracy for 1 task(s): \t [Class-IL]: 56.25 % \t [Task-IL]: 0.0 %\n",
      "\tRaw accuracy values: Class-IL [56.25] | Task-IL [0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  1  at index:  0\n",
      "Applying BiLORA technique for current task:  1  at index:  0\n",
      "Applying BiLORA technique for current task:  1  at index:  0\n",
      "begin task 2, dataset:seq-cifar100\n",
      "target classes:  [89, 54, 34, 83, 33]\n",
      "[INFO] 10-Jan-26 19:50:11 - Using 8 workers for the dataloader.\n",
      "target classes:  [89, 54, 34, 83, 33]\n",
      "[INFO] 10-Jan-26 19:50:12 - Using 8 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Choose params for task 2: 100%|██████████| 50/50 [00:09<00:00,  5.05it/s, distances=[0.73]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load expert 1 parameters\n",
      "Create new expert 2\n",
      "Applying BiLORA technique for current task:  1  at index:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 2 - Epoch 5: 100%|█████████████████████████████████████████████████████████████| 390/390 [07:21<00:00,  1.13s/it, loss_ce=2.84, loss_kd=-0.21, loss_nor=-0.0738, loss_mi=0.439, lr=0.03, ep/h=40.8]\n",
      "Calculate distribution for task 2:  78%|███████▊  | 78/100 [00:14<00:04,  5.22it/s]\n",
      "Choose expert for evaluate: 100%|████████████████████████████████████████████████████████████████████████| 30/30 [00:06<00:00,  4.46it/s, task 2=1, distance=[4.83, 5.43]]\n",
      "Evaluating:   0%|                                                                                                                                  | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose experts for evaluate: [1, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 1:  10%|█████████▊                                                                                        | 3/30 [00:02<00:19,  1.41it/s, acc_task_1=4.17]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  2  at index:  0\n",
      "Applying BiLORA technique for current task:  2  at index:  0\n",
      "Applying BiLORA technique for current task:  2  at index:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 2:  20%|████████████████████▏                                                                                | 6/30 [00:04<00:18,  1.27it/s, acc_task_2=0]\n",
      "Accuracy for 2 task(s): \t [Class-IL]: 2.08 % \t [Task-IL]: 0.0 %\n",
      "\tRaw accuracy values: Class-IL [4.166666666666666, 0.0] | Task-IL [0, 0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  2  at index:  0\n",
      "Applying BiLORA technique for current task:  2  at index:  0\n",
      "Applying BiLORA technique for current task:  2  at index:  0\n",
      "begin task 3, dataset:seq-cifar100\n",
      "target classes:  [82, 10, 87, 69, 8]\n",
      "[INFO] 10-Jan-26 19:58:13 - Using 8 workers for the dataloader.\n",
      "target classes:  [82, 10, 87, 69, 8]\n",
      "[INFO] 10-Jan-26 19:58:14 - Using 8 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Choose params for task 3: 100%|██████████| 50/50 [00:10<00:00,  4.93it/s, distances=[0.66, 7.25]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load expert 1 parameters\n",
      "Create new expert 3\n",
      "Applying BiLORA technique for current task:  2  at index:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 3 - Epoch 5: 100%|████████████████████████████████████████████████████████| 390/390 [07:28<00:00,  1.15s/it, loss_ce=0.00488, loss_kd=-0.456, loss_nor=-0.0317, loss_mi=0.0228, lr=0.03, ep/h=40.4]\n",
      "Calculate distribution for task 3:  78%|███████▊  | 78/100 [00:15<00:04,  5.18it/s]\n",
      "Choose expert for evaluate: 100%|█████████████████████████████████████████████████████████████████| 45/45 [00:10<00:00,  4.33it/s, task 3=3, distance=[2.51, 31.27, 1.77]]\n",
      "Evaluating:   0%|                                                                                                                                  | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose experts for evaluate: [1, 1, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 1:   7%|██████▋                                                                                              | 3/45 [00:02<00:32,  1.30it/s, acc_task_1=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  3  at index:  0\n",
      "Applying BiLORA technique for current task:  3  at index:  0\n",
      "Applying BiLORA technique for current task:  3  at index:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 2:  13%|█████████████▍                                                                                       | 6/45 [00:05<00:30,  1.26it/s, acc_task_2=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  3  at index:  0\n",
      "Applying BiLORA technique for current task:  3  at index:  0\n",
      "Applying BiLORA technique for current task:  3  at index:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 3:  20%|███████████████████▌                                                                              | 9/45 [00:07<00:31,  1.14it/s, acc_task_3=77.1]\n",
      "Accuracy for 3 task(s): \t [Class-IL]: 25.69 % \t [Task-IL]: 0.0 %\n",
      "\tRaw accuracy values: Class-IL [0.0, 0.0, 77.08333333333334] | Task-IL [0, 0, 0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "System stats:\n",
      "\tInitial CPU memory usage: 2648.54 MB\n",
      "\tAverage CPU memory usage: 3803.34 MB\n",
      "\tFinal CPU memory usage: 4575.53 MB\n",
      "\tMax CPU memory usage: 4573.12 MB\n",
      "\tInitial GPU 0 memory usage: 1084.00 MB\n",
      "\tAverage GPU 0 memory usage: 8914.00 MB\n",
      "\tFinal GPU 0 memory usage: 8914.00 MB\n",
      "\tMax GPU 0 memory usage: 8914.00 MB\n",
      "Logging results and arguments in ./data/results/class-il/seq-cifar100/LEAR/logs.pyd\n",
      "[INFO CMD] Running:  python main_domain.py --list_datasets seq-cifar100,seq-cifar100,seq-cifar100 --dataset seq-cifar100 --ncls_per_task 5 --model LEAR --lr 0.03 --batch_size 32 --n_epochs 5 --num_workers 8 --backbone lear --transform_type weak --use_bilora 1 --apply_bilora_for both --bilora_mode aggregate --skip_task_0 1\n",
      "[INFO] 10-Jan-26 20:06:30 - Running Mammoth! on 04dc83e5ff9c. (if you see this message more than once, you are probably importing something wrong)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 10-Jan-26 20:06:33 - NumExpr defaulting to 4 threads.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (4.4.4) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] 10-Jan-26 20:06:34 - Trying to load default configuration for model LEAR but no configuration file found in None.\n",
      "[WARNING] 10-Jan-26 20:06:34 - Default configuration file not found for dataset seq-cifar100. Using the defaults specified in the dataset class (if available).\n",
      "[INFO] 10-Jan-26 20:06:34 - `lr_scheduler` set to multisteplr, overrides default from dataset.\n",
      "[INFO] 10-Jan-26 20:06:34 - Using device cuda:0\n",
      "Loading dataset: seq-cifar100\n",
      "Loading dataset: seq-cifar100\n",
      "Loading dataset: seq-cifar100\n",
      "[INFO] 10-Jan-26 20:06:34 - `wandb_entity` and `wandb_project` not set. Disabling wandb.\n",
      "[WARNING] 10-Jan-26 20:06:34 - Label noise is not available with multi-label datasets. If this is not multi-label, ignore this warning.\n",
      "[INFO] 10-Jan-26 20:06:36 - Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)\n",
      "[INFO] 10-Jan-26 20:06:36 - [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "[INFO] 10-Jan-26 20:06:36 - Missing keys (head.weight, head.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n",
      "[INFO] 10-Jan-26 20:06:37 - Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)\n",
      "[INFO] 10-Jan-26 20:06:38 - [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "[INFO] 10-Jan-26 20:06:38 - Missing keys (head.weight, head.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n",
      "[INFO] 10-Jan-26 20:06:38 - Using backbone: lear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LEAR as backbone\n",
      "Use BiLORA:  True\n",
      "Apply BiLORA for:  both\n",
      "Namespace(dataset='seq-cifar100', model='LEAR', backbone='lear', load_best_args=False, dataset_config=None, model_config='default', list_datasets='seq-cifar100,seq-cifar100,seq-cifar100', transform_type='weak', ncls_per_task=5, use_bilora=1, apply_bilora_for='both', skip_task_0=1, bilora_mode='aggregate', num_classes=100, seed=None, permute_classes=False, base_path='./data/', results_path='results/', device=device(type='cuda', index=0), notes=None, eval_epochs=None, non_verbose=False, disable_log=False, num_workers=8, enable_other_metrics=False, debug_mode=False, inference_only=False, code_optimization=0, distributed='no', savecheck=None, save_checkpoint_mode='safe', loadcheck=None, ckpt_name=None, start_from=None, stop_after=None, wandb_name=None, wandb_entity=None, wandb_project=None, lr=0.03, batch_size=32, label_perc=1.0, label_perc_by_class=1.0, joint=0, eval_future=False, validation=None, validation_mode='current', fitting_mode='epochs', early_stopping_patience=5, early_stopping_metric='loss', early_stopping_freq=1, early_stopping_epsilon=1e-06, n_epochs=5, n_iters=None, optimizer='sgd', optim_wd=0.0, optim_mom=0.0, optim_nesterov=False, drop_last=False, lr_scheduler='multisteplr', scheduler_mode='epoch', lr_milestones=[35, 45], sched_multistep_lr_gamma=0.1, noise_type='symmetric', noise_rate=0.0, disable_noisy_labels_cache=False, cache_path_noisy_labels='noisy_labels', conf_jobnum='a8b48a41-b3e9-4226-b834-3bdc802b837b', conf_timestamp='2026-01-10 20:06:34.781020', conf_host='04dc83e5ff9c', conf_git_hash='d9141df2a3954ab461ad96da8cee30a4693fe2d0', minibatch_size=32, nowand=1)\n",
      "begin task 1, dataset:seq-cifar100\n",
      "target classes:  [42, 16, 5, 32, 86]\n",
      "[INFO] 10-Jan-26 20:06:41 - Using 8 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target classes:  [42, 16, 5, 32, 86]\n",
      "[INFO] 10-Jan-26 20:06:42 - Using 8 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 1 - Epoch 5: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 390/390 [03:45<00:00,  1.73it/s, loss_ce=0.000514, loss_nor=-0.0322, lr=0.03, ep/h=80]\n",
      "Calculate distribution for task 1:  78%|███████▊  | 78/100 [00:14<00:04,  5.42it/s]\n",
      "Evaluating:   0%|                                                                                                                                  | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose experts for evaluate: [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 1:  20%|███████████████████▌                                                                              | 3/15 [00:02<00:09,  1.28it/s, acc_task_1=46.9]\n",
      "Accuracy for 1 task(s): \t [Class-IL]: 46.88 % \t [Task-IL]: 0.0 %\n",
      "\tRaw accuracy values: Class-IL [46.875] | Task-IL [0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  1  at index:  0\n",
      "Applying BiLORA technique for current task:  1  at index:  0\n",
      "Applying BiLORA technique for current task:  1  at index:  0\n",
      "begin task 2, dataset:seq-cifar100\n",
      "target classes:  [83, 33, 54, 43, 55]\n",
      "[INFO] 10-Jan-26 20:10:46 - Using 8 workers for the dataloader.\n",
      "target classes:  [83, 33, 54, 43, 55]\n",
      "[INFO] 10-Jan-26 20:10:47 - Using 8 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Choose params for task 2: 100%|██████████| 50/50 [00:09<00:00,  5.07it/s, distances=[0.95]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load expert 1 parameters\n",
      "Create new expert 2\n",
      "Applying BiLORA technique for current task:  1  at index:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 2 - Epoch 5: 100%|████████████████████████████████████████████████████████████| 390/390 [07:15<00:00,  1.12s/it, loss_ce=0.163, loss_kd=-1.41, loss_nor=-0.0323, loss_mi=0.683, lr=0.03, ep/h=41.5]\n",
      "Calculate distribution for task 2:  78%|███████▊  | 78/100 [00:14<00:04,  5.22it/s]\n",
      "Choose expert for evaluate: 100%|████████████████████████████████████████████████████████████████████████| 30/30 [00:06<00:00,  4.48it/s, task 2=2, distance=[3.87, 1.89]]\n",
      "Evaluating:   0%|                                                                                                                                  | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose experts for evaluate: [2, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 1:  10%|██████████                                                                                           | 3/30 [00:02<00:19,  1.36it/s, acc_task_1=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  2  at index:  1\n",
      "Applying BiLORA technique for current task:  2  at index:  1\n",
      "Applying BiLORA technique for current task:  2  at index:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 2:  20%|███████████████████▌                                                                              | 6/30 [00:04<00:19,  1.25it/s, acc_task_2=94.8]\n",
      "Accuracy for 2 task(s): \t [Class-IL]: 47.4 % \t [Task-IL]: 0.0 %\n",
      "\tRaw accuracy values: Class-IL [0.0, 94.79166666666666] | Task-IL [0, 0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  2  at index:  1\n",
      "Applying BiLORA technique for current task:  2  at index:  1\n",
      "Applying BiLORA technique for current task:  2  at index:  1\n",
      "begin task 3, dataset:seq-cifar100\n",
      "target classes:  [42, 7, 56, 46, 55]\n",
      "[INFO] 10-Jan-26 20:18:42 - Using 8 workers for the dataloader.\n",
      "target classes:  [42, 7, 56, 46, 55]\n",
      "[INFO] 10-Jan-26 20:18:43 - Using 8 workers for the dataloader.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Choose params for task 3: 100%|██████████| 50/50 [00:10<00:00,  4.92it/s, distances=[0.99, 0.67]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load expert 2 parameters\n",
      "Create new expert 3\n",
      "Applying BiLORA technique for current task:  2  at index:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 3 - Epoch 5: 100%|████████████████████████████████████████████████████████████| 390/390 [07:29<00:00,  1.15s/it, loss_ce=0.0458, loss_kd=-1.6, loss_nor=-0.0208, loss_mi=0.104, lr=0.03, ep/h=40.3]\n",
      "Calculate distribution for task 3:  78%|███████▊  | 78/100 [00:15<00:04,  5.16it/s]\n",
      "Choose expert for evaluate: 100%|███████████████████████████████████████████████████████████████████| 45/45 [00:10<00:00,  4.30it/s, task 3=3, distance=[3.0, 2.41, 1.82]]\n",
      "Evaluating:   0%|                                                                                                                                  | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose experts for evaluate: [3, 2, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 1:   7%|██████▌                                                                                           | 3/45 [00:02<00:31,  1.33it/s, acc_task_1=17.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "Applying BiLORA technique for current task:  3  at index:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 2:  13%|█████████████                                                                                     | 6/45 [00:04<00:30,  1.27it/s, acc_task_2=66.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  3  at index:  1\n",
      "Applying BiLORA technique for current task:  3  at index:  1\n",
      "Applying BiLORA technique for current task:  3  at index:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 3:  20%|███████████████████▌                                                                              | 9/45 [00:07<00:31,  1.14it/s, acc_task_3=87.5]\n",
      "Accuracy for 3 task(s): \t [Class-IL]: 57.29 % \t [Task-IL]: 0.0 %\n",
      "\tRaw accuracy values: Class-IL [17.708333333333336, 66.66666666666666, 87.5] | Task-IL [0, 0, 0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "Applying BiLORA technique for current task:  3  at index:  2\n",
      "System stats:\n",
      "\tInitial CPU memory usage: 2648.73 MB\n",
      "\tAverage CPU memory usage: 3777.44 MB\n",
      "\tFinal CPU memory usage: 4571.80 MB\n",
      "\tMax CPU memory usage: 4562.64 MB\n",
      "\tInitial GPU 0 memory usage: 1084.00 MB\n",
      "\tAverage GPU 0 memory usage: 8888.00 MB\n",
      "\tFinal GPU 0 memory usage: 8888.00 MB\n",
      "\tMax GPU 0 memory usage: 8888.00 MB\n",
      "Logging results and arguments in ./data/results/class-il/seq-cifar100/LEAR/logs.pyd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for cmd in list_cmds:\n",
    "    try:\n",
    "        print(\"[INFO CMD] Running: \", cmd)    \n",
    "        os.system(cmd)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9496.227043,
   "end_time": "2026-01-10T20:27:00.363622",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-10T17:48:44.136579",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
